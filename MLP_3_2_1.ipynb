{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "MLP_3_2_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danccas/SPAM-Detector/blob/master/MLP_3_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB0-MW-C7rHA",
        "colab_type": "text"
      },
      "source": [
        "**Perceptrón Multicapa**\n",
        "\n",
        " En esta prueba modificaremos nuestro MLP según las capas **3:2:1**,\n",
        " utilizaremos un vector de características para representar un texto.\n",
        "\n",
        "Nuestra finalidad es clasificar automáticamente los textos y determinar su eficiencia en términos de accuracy o exactitud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XIrBayn7y-D",
        "colab_type": "text"
      },
      "source": [
        "**Librerias:**\n",
        "\n",
        "Vamos a realizar la importación de librerias necesarias para aplicar nuestro MLP, y procesos como la vectorización y clasificación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBouJSxKefjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b23b5130-0870-4f0a-b46d-6a9add371300"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import PorterStemmer as Stemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYeIH8BMpJam",
        "colab_type": "text"
      },
      "source": [
        "Vamos a instalar nltk, de esta forma realizaremos una limpieza del texto previa a su vertorización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4__U63ipLWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "994a264a-6b40-4a0d-ff29-d0aaffbc591c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv18UhYRnLov",
        "colab_type": "text"
      },
      "source": [
        "Vamos a montar nuestro disco Drive, donde tenemos nuestro dataset de spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzp_TB3inN5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "20278f2c-be20-4f6f-c302-85f05f9f1fc9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coykOSEGnTUs",
        "colab_type": "text"
      },
      "source": [
        "**Dataset:**\n",
        "\n",
        "Hemos usado el dataset de Kaggle, un reconocido repositorio, el cual nos provee 5572 lineas de mensajes etiquetados para su posterior aprendizaje.\n",
        "\n",
        "Link: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
        "\n",
        "\n",
        "Importamos el dataset asignando dos columnas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1hSpgm8efjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "005e94bd-07f1-43d2-df19-50a2017171e3"
      },
      "source": [
        "read_file  = pd.read_csv('gdrive/My Drive/Colab Notebooks/SOM/datasets_483_982_spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "read_file.columns = ['label', 'message']\n",
        "read_file.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4-xalBefjM",
        "colab_type": "text"
      },
      "source": [
        "Devuelve una tupla que representa la dimensionalidad del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro_dDVCVefjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8ca5aa9-91e6-4573-9c4b-3f63c22437ba"
      },
      "source": [
        "read_file.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdywS8yYoPP4",
        "colab_type": "text"
      },
      "source": [
        "Vamos a realizar un agrupamiento por la etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qJnh7PkefjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3600ca48-a038-4a3e-f43b-11c2890eac1c"
      },
      "source": [
        "read_file.groupby('label').describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">message</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>4825</td>\n",
              "      <td>4516</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>747</td>\n",
              "      <td>653</td>\n",
              "      <td>Please call our customer service representativ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      message                                                               \n",
              "        count unique                                                top freq\n",
              "label                                                                       \n",
              "ham      4825   4516                             Sorry, I'll call later   30\n",
              "spam      747    653  Please call our customer service representativ...    4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmb2FUWeoWiG",
        "colab_type": "text"
      },
      "source": [
        "Realziaremos una grafica del agrupamiento binario ham/spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBXmYkh4efjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d9a71713-2e69-4bf7-a13e-8ab6e0df70d2"
      },
      "source": [
        "sns.countplot(data=read_file, x='label') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc2f275e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfC6RI-cefjX",
        "colab_type": "text"
      },
      "source": [
        "**Procesamiento de Texto:**\n",
        "\n",
        "Limpiar y normalizar texto, se realiza los siguientes pasos:\n",
        "\n",
        "1.   Eliminar signos de puntuación\n",
        "2.   Eliminar todas las palabras vacías\n",
        "3.   Aplicar derivación (conversión a forma normal de palabra). Por ejemplo, 'conduciendo automóvil' y 'conduces automóvil' se convierte en conducir automóvil\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Zp-EVdefjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a54ae067-12dd-48e3-e202-bafadc577c0e"
      },
      "source": [
        "def text_processing(text_):\n",
        "    text_ = text_.lower()\n",
        "    text_ = ''.join([i for i in text_ if i not in string.punctuation])\n",
        "    text_ = [i for i in text_.split() if i not in stopwords.words('english')]\n",
        "    string_ = Stemmer()\n",
        "    text_ = [string_.stem(i) for i in text_]\n",
        "    return text_ \n",
        "\n",
        "text_processing('driving car')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive', 'car']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSvz4uvKefjb",
        "colab_type": "text"
      },
      "source": [
        "Utilizaremos TfidfVectorizer. Convertirá la colección de documentos de texto (corpus de SMS) en una matriz 2D. Una dimensión representa documentos y otra dimensión repite cada palabra única en el corpus de SMS..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpMI5kP5efjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidfv = TfidfVectorizer(analyzer=text_processing)  # Tfid\n",
        "data_processing = tfidfv.fit_transform(read_file['message'])\n",
        "type(data_processing)\n",
        "data_processing = data_processing.toarray()  # convertirmos la matriz a un array para el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnjJI5O4efjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71110a49-4097-4465-ca87-faaf236f8578"
      },
      "source": [
        "data_processing.shape  # comprobar la forma de la matriz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 8097)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVg7Zypdefji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels =  read_file['label']  # almacena etiquetas en otra variable para que podamos usarlo para entrenamiento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6AEYaYjefjl",
        "colab_type": "text"
      },
      "source": [
        "**Aprendizaje y Predicción:**\n",
        "\n",
        "1. El algoritmo escogido para la solución es un optimizador estocástico basado en gradiente propuesto por Kingma, Diederik y Jimmy Ba.\n",
        "2. La función de activación de la capa oculpa escogida es la función tan hiperbólica, devuelve f (x) = tanh (x)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crCQS_mEefjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_processing, labels, stratify=labels)\n",
        "model = MLPClassifier(solver='adam', activation='tanh', alpha=1e-5, hidden_layer_sizes=(3, 2, 1), random_state=1, max_iter=500)\n",
        "model = model.fit(X_train, y_train)  # Entrenar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQGQihdzefjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict(X_test)  # Predecir "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg_ZTyuoefjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d154a5b0-08a3-41d5-90b1-d28f0d82953e"
      },
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1206\n",
            "        spam       0.98      0.88      0.93       187\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.94      0.96      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yriPv-Go9vVH",
        "colab_type": "text"
      },
      "source": [
        "**Conclusión:**\n",
        "\n",
        "*MLP 2:2:1*: Se tiene una precisión del 99% en la predicción del ham, así como 96% para spam. Teniendo una precisión total de 97%.\n",
        "\n",
        "*MLP 3:2:1*: Se tiene una precisión del 98% en la predicción del ham, así como 98% para spam. Teniendo una precisión total de 98%.\n",
        "\n",
        "*MLP 3:3:1*: Se tiene una precisión del 99% en la predicción del ham, así como 97% para spam. Teniendo una precisión total de 98%.\n",
        "\n",
        "**Se concluye que los MLP 3:2:1 y 3:3:1 tienen una mayor precisión en la predicción de spam y ham.**"
      ]
    }
  ]
}